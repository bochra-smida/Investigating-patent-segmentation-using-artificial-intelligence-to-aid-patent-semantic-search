{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtual env: (base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importings and Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmHG5DJfsEte"
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tI22wFrZBZWn",
    "outputId": "a945be54-7c5f-430c-ad82-c606c190aec6"
   },
   "outputs": [],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule based methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oLhN2CsWsdlT"
   },
   "outputs": [],
   "source": [
    "def find_claim_numbers(claim_text):\n",
    "    #return: A list of integers with the positions in the string of the start of each claim.\n",
    "    if type(claim_text)!= str:\n",
    "        claim_text = str(claim_text)\n",
    "    size = len(claim_text)\n",
    "    positions = []\n",
    "    current = 0\n",
    "    claim_no = 1\n",
    "    claim_marker = create_claim_marker(claim_no)\n",
    "    while current < size:\n",
    "        if claim_text[current: current + len(claim_marker)] == claim_marker:\n",
    "            positions.append(current)\n",
    "            claim_no += 1\n",
    "            claim_marker = create_claim_marker(claim_no)\n",
    "        current += 1\n",
    "    if len(positions) == 0:\n",
    "        positions = [0]\n",
    "    return positions\n",
    "\n",
    "\n",
    "def create_claim_marker(claim_no):  \n",
    "    #return: The string that matches the placement of that claim in the text of a patent's claims document.\n",
    "    return str(claim_no) + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xmM3TUqIshPh"
   },
   "outputs": [],
   "source": [
    "def convert_claim_text(claim_text):\n",
    "    \"\"\"\n",
    "    This method takes the text of the patent claims and then converts them into a dictionary where the keys are the\n",
    "    claim numbers and the values are a list of strings.  Each item in the list is a clause of the patent claim, and the\n",
    "    clauses are listed in the order in which they are provided by the claim.\n",
    "    \"\"\"\n",
    "    # Dictionary object to store the claims\n",
    "    claim_text_dict = {}\n",
    "    claim_number_positions = find_claim_numbers(claim_text)\n",
    "    for i in range(len(claim_number_positions)):\n",
    "        current_claim_number = str(i+1)\n",
    "\n",
    "        # We slice the text starting after the number where the text starts up to the next number.\n",
    "        if i != len(claim_number_positions) - 1:\n",
    "            claim_text_dict[current_claim_number] = claim_text[claim_number_positions[i] + len(current_claim_number) + 2:claim_number_positions[i+1]]\n",
    "\n",
    "        # To prevent an index error for the last claim we slice to the remainder of the text\n",
    "        else:\n",
    "            claim_text_dict[current_claim_number] = claim_text[claim_number_positions[i] + len(current_claim_number) + 2:]\n",
    "    claim_text_dict = {int(k):v for k,v in claim_text_dict.items()}\n",
    "\n",
    "\n",
    "    return claim_text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1zkGx8JTsjmA"
   },
   "outputs": [],
   "source": [
    "def create_node(root,components,relations):\n",
    "    #return a dictionary with component specification\n",
    "    d = {}\n",
    "    d['root'] = root\n",
    "    d['components'] = components\n",
    "    d['relations'] = relations\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ESA7sIyh5F_M"
   },
   "outputs": [],
   "source": [
    "def get_claim_type(claim):\n",
    "    #this method returns if the claim is a method or apparatus claim\n",
    "    first_phrase = claim[:20]\n",
    "    if 'method' in first_phrase:\n",
    "        return 'method'\n",
    "    return 'apparatus'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qwWUyMdo7RQQ"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "punctuation_match = 0\n",
    "res = []\n",
    "def create_subtree(row):\n",
    "    global punctuation_match\n",
    "    global res\n",
    "    #create only subtree for independant claim 1\n",
    "    claim = row['claims_text_dict'][1]\n",
    "    print(row.name)\n",
    "    #initialisation\n",
    "    relations = ''  \n",
    "    regex_ex = re.compile(r'(.*?) comprising:, ((.*?);){1,}(.*?).,', re.VERBOSE | re.IGNORECASE)\n",
    "    \n",
    "    #if there is punctuation, we segment using punctuation\n",
    "    if not claim.endswith('.,'):\n",
    "        claim = claim + '.,'\n",
    "    if regex_ex.fullmatch(claim):\n",
    "        punctuation_match += 1\n",
    "        #we should not delete comprising and we don't use split because it can be multiple \"comprising\" in claim\n",
    "        root = claim[:claim.index(\"comprising\") + len('comprising')].strip()\n",
    "        elements = claim[claim.index(\"comprising\") + len('comprising'):].strip().split(';')\n",
    "        elements = [elt + ';' for elt in elements]\n",
    "        if 'wherein' in elements[-1]:\n",
    "            relations = elements[-1][elements[-1].index('wherein')+len('wherein'):]\n",
    "            elements[-1] = elements[-1][:elements[-1].index('wherein')+len('wherein')]\n",
    "\n",
    "    else:\n",
    "        if 'wherein' in claim and 'comprising' not in claim:\n",
    "            root = claim.split('wherein')[0]\n",
    "            elements = claim.split('wherein')[0]\n",
    "            if 'comprising' in elements:\n",
    "                elements = elements.split('comprising')[1].replace('\\n ',\"\").replace(',','').split(';')\n",
    "                relations = claim.split('wherein')[1]\n",
    "        elif 'comprising' in claim:\n",
    "            root = claim.split('comprising')[0]\n",
    "            elements = claim[claim.index(\"comprising\") + len('comprising'):].strip().split(';')\n",
    "        else:\n",
    "            elements = []\n",
    "            root = claim\n",
    "\n",
    "\n",
    "    #clean root the root (define line break for purpose of invention)\n",
    "    if 'for' in root:\n",
    "        if len(TextBlob(root).noun_phrases) > 0:\n",
    "            root = root.split('for')[0] + ' [LB] for' + root.split('for')[1]\n",
    "\n",
    "    for elt in elements:\n",
    "        #search for noun if they begin with ['a','an'] or ['the','said'] to classify them as sub-elements\n",
    "        #print('elt',elt)\n",
    "        doc = nlp(elt.strip())\n",
    "        L = list(doc.noun_chunks)[1:]\n",
    "\n",
    "        #convert type of spacy object to str\n",
    "        for i in range(len(L)):\n",
    "            L[i] = str(L[i])\n",
    "\n",
    "        #create '[sub]' tag to sub-elements  \n",
    "        new_elt = elt\n",
    "        for se in L:\n",
    "            if se.startswith('a') and elt.replace('[1-9 a-z A-Z] \\)','') != 0:\n",
    "                new_elt = new_elt.replace(se,'[sub] '+se)\n",
    "        #elements.replace(elt,new_elt)\n",
    "        elements = list(map(lambda x: x.replace(elt,new_elt),elements))\n",
    "        #print(elt)\n",
    "        res.append(create_node(root,elements,relations))\n",
    "    return create_node(root,elements,relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments_list(claim_tree):\n",
    "    #this function takes the claim tree as input and returns 2 lists one being the segments and the other one has the same \n",
    "    #length as the first one and indicates whether or not each segment ends a sentence.\n",
    "    if type(claim_tree) == str:\n",
    "        claim_tree = ast.literal_eval(claim_tree)\n",
    "    root_result = []\n",
    "    components_result = []\n",
    "    relations_result = []\n",
    "    components_result_binary = []\n",
    "    root_result = claim_tree['root'].split()\n",
    "    for component in claim_tree['components']:\n",
    "        components_result.append(component.split())\n",
    "        components_result_binary.append([0 for i in range(len(component.split())-1) ] + [1])\n",
    "    components_result = [item for sublist in components_result for item in sublist]\n",
    "    components_result_binary = [item for sublist in components_result_binary for item in sublist]\n",
    "    relations_result = claim_tree['relations'].split()\n",
    "    final_result = root_result + components_result + relations_result\n",
    "    final_result_binary = [0 for i in range(len(root_result)-1)] + [1] + components_result_binary + [0 for i in range(len(relations_result))]\n",
    "    for k in range(len(final_result)):\n",
    "        if final_result[k] == '[LB]' or final_result[k] == '[sub]':\n",
    "            if k > 0:\n",
    "                final_result_binary[k-1] = 1\n",
    "                \n",
    "    index_remove = [idx for idx, x in enumerate(final_result) if x == \"[sub]\" or x == \"[LB]\"]\n",
    "    if index_remove:\n",
    "        final_result = [ele for idx, ele in enumerate(final_result) if idx not in index_remove]\n",
    "        final_result_binary = [ele for idx, ele in enumerate(final_result_binary) if idx not in index_remove]\n",
    "    return final_result, final_result_binary\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply rule based methods to segment the claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "G_M2Cp18pH6k"
   },
   "outputs": [],
   "source": [
    "#read document\n",
    "df = pd.read_csv('./uspto_df')\n",
    "#clean claim_text from NaN values\n",
    "df = df[df['claims_text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>grant_id</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>kind</th>\n",
       "      <th>number_of_claims</th>\n",
       "      <th>inventors</th>\n",
       "      <th>citations_applicant_count</th>\n",
       "      <th>citations_examiner_count</th>\n",
       "      <th>claims_text</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>USD0961886</td>\n",
       "      <td>Candy</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>['Rhett Vance Barney', 'Chad Taylor Robinson',...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>The ornamental design for candy, as shown and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>USD0961887</td>\n",
       "      <td>Garment</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>['Wenchang Hu']</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>The ornamental design for a garment, as shown ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>USD0961888</td>\n",
       "      <td>Vest</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>['Izzy Benoliel']</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>The ornamental design for a vest, as shown and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>USD0961889</td>\n",
       "      <td>Headband with LED lights</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>['Joshua Chen']</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>The ornamental design for a headband with LED ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>USD0961890</td>\n",
       "      <td>Backless baseball cap</td>\n",
       "      <td>Design Patent</td>\n",
       "      <td>1</td>\n",
       "      <td>['Adrienne Walker']</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>The ornamental design for a backless ball cap,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    grant_id              patent_title           kind  \\\n",
       "0           0  USD0961886                     Candy  Design Patent   \n",
       "1           1  USD0961887                   Garment  Design Patent   \n",
       "2           2  USD0961888                      Vest  Design Patent   \n",
       "3           3  USD0961889  Headband with LED lights  Design Patent   \n",
       "4           4  USD0961890     Backless baseball cap  Design Patent   \n",
       "\n",
       "   number_of_claims                                          inventors  \\\n",
       "0                 1  ['Rhett Vance Barney', 'Chad Taylor Robinson',...   \n",
       "1                 1                                    ['Wenchang Hu']   \n",
       "2                 1                                  ['Izzy Benoliel']   \n",
       "3                 1                                    ['Joshua Chen']   \n",
       "4                 1                                ['Adrienne Walker']   \n",
       "\n",
       "   citations_applicant_count  citations_examiner_count  \\\n",
       "0                          2                        10   \n",
       "1                          0                         9   \n",
       "2                          0                        11   \n",
       "3                          0                        26   \n",
       "4                          1                        21   \n",
       "\n",
       "                                         claims_text abstract  \n",
       "0  The ornamental design for candy, as shown and ...      NaN  \n",
       "1  The ornamental design for a garment, as shown ...      NaN  \n",
       "2  The ornamental design for a vest, as shown and...      NaN  \n",
       "3  The ornamental design for a headband with LED ...      NaN  \n",
       "4  The ornamental design for a backless ball cap,...      NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[150000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "z3w7Z9zGpDQK"
   },
   "outputs": [],
   "source": [
    "claim_text_dict = df['claims_text'].apply(convert_claim_text)\n",
    "df['claims_text_dict'] = claim_text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4o_4cUPTAEbr"
   },
   "outputs": [],
   "source": [
    "claim_subtree = df.apply(create_subtree,axis=1)\n",
    "df['claim_tree'] = claim_subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BRbnqbDqtUXi"
   },
   "outputs": [],
   "source": [
    "df['claim_tree'] = claim_subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "JuROP3wUuBwA",
    "outputId": "2011880a-0315-4300-c521-9d84f16cb9e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>grant_id</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>kind</th>\n",
       "      <th>number_of_claims</th>\n",
       "      <th>inventors</th>\n",
       "      <th>citations_applicant_count</th>\n",
       "      <th>citations_examiner_count</th>\n",
       "      <th>claims_text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims_text_dict</th>\n",
       "      <th>claim_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150001</th>\n",
       "      <td>150001</td>\n",
       "      <td>US11300077</td>\n",
       "      <td>Deployable fairing for door reversers systems ...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>8</td>\n",
       "      <td>['Timothy Gormley']</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1. An actuation arrangement for a thrust rever...</td>\n",
       "      <td>A thrust reverser may include a frame, an actu...</td>\n",
       "      <td>{1: 'An actuation arrangement for a thrust rev...</td>\n",
       "      <td>{'root': 'An actuation arrangement  [LB] for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150002</th>\n",
       "      <td>150002</td>\n",
       "      <td>US11300078</td>\n",
       "      <td>Variable thrust catapult</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>['Jeff Benjamin', 'Matthew D. Salois']</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1. A rocket catapult assembly for use in an ej...</td>\n",
       "      <td>A rocket catapult assembly for an ejection sea...</td>\n",
       "      <td>{1: 'A rocket catapult assembly for use in an ...</td>\n",
       "      <td>{'root': 'A rocket catapult assembly  [LB] for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150003</th>\n",
       "      <td>150003</td>\n",
       "      <td>US11300079</td>\n",
       "      <td>Diagnostic apparatus for evaporative fuel proc...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>10</td>\n",
       "      <td>['Daisuke Kugo', 'Masahiro Ono']</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1. A diagnostic apparatus for an evaporative f...</td>\n",
       "      <td>A diagnostic apparatus for an evaporative fuel...</td>\n",
       "      <td>{1: 'A diagnostic apparatus for an evaporative...</td>\n",
       "      <td>{'root': 'A diagnostic apparatus  [LB] for an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150004</th>\n",
       "      <td>150004</td>\n",
       "      <td>US11300080</td>\n",
       "      <td>Fuel tank protector valve and engine systems h...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>20</td>\n",
       "      <td>['Chester E. Duffield, III']</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1. A fuel tank protector valve comprising:,a h...</td>\n",
       "      <td>A dual chamber fuel tank protector valve has a...</td>\n",
       "      <td>{1: 'A fuel tank protector valve comprising:,a...</td>\n",
       "      <td>{'root': 'A fuel tank protector valve comprisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150005</th>\n",
       "      <td>150005</td>\n",
       "      <td>US11300081</td>\n",
       "      <td>Engine intake bypass system</td>\n",
       "      <td>Utility Patent Grant (no published application...</td>\n",
       "      <td>10</td>\n",
       "      <td>['Il Suk Yang']</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1. An engine intake bypass system comprising:,...</td>\n",
       "      <td>An engine intake bypass system includes: an in...</td>\n",
       "      <td>{1: 'An engine intake bypass system comprising...</td>\n",
       "      <td>{'root': 'An engine intake bypass system compr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    grant_id  \\\n",
       "150001      150001  US11300077   \n",
       "150002      150002  US11300078   \n",
       "150003      150003  US11300079   \n",
       "150004      150004  US11300080   \n",
       "150005      150005  US11300081   \n",
       "\n",
       "                                             patent_title  \\\n",
       "150001  Deployable fairing for door reversers systems ...   \n",
       "150002                           Variable thrust catapult   \n",
       "150003  Diagnostic apparatus for evaporative fuel proc...   \n",
       "150004  Fuel tank protector valve and engine systems h...   \n",
       "150005                        Engine intake bypass system   \n",
       "\n",
       "                                                     kind  number_of_claims  \\\n",
       "150001  Utility Patent Grant (with a published applica...                 8   \n",
       "150002  Utility Patent Grant (with a published applica...                20   \n",
       "150003  Utility Patent Grant (with a published applica...                10   \n",
       "150004  Utility Patent Grant (with a published applica...                20   \n",
       "150005  Utility Patent Grant (no published application...                10   \n",
       "\n",
       "                                     inventors  citations_applicant_count  \\\n",
       "150001                     ['Timothy Gormley']                         27   \n",
       "150002  ['Jeff Benjamin', 'Matthew D. Salois']                          2   \n",
       "150003        ['Daisuke Kugo', 'Masahiro Ono']                         13   \n",
       "150004            ['Chester E. Duffield, III']                          3   \n",
       "150005                         ['Il Suk Yang']                          1   \n",
       "\n",
       "        citations_examiner_count  \\\n",
       "150001                         1   \n",
       "150002                         4   \n",
       "150003                         4   \n",
       "150004                        25   \n",
       "150005                         2   \n",
       "\n",
       "                                              claims_text  \\\n",
       "150001  1. An actuation arrangement for a thrust rever...   \n",
       "150002  1. A rocket catapult assembly for use in an ej...   \n",
       "150003  1. A diagnostic apparatus for an evaporative f...   \n",
       "150004  1. A fuel tank protector valve comprising:,a h...   \n",
       "150005  1. An engine intake bypass system comprising:,...   \n",
       "\n",
       "                                                 abstract  \\\n",
       "150001  A thrust reverser may include a frame, an actu...   \n",
       "150002  A rocket catapult assembly for an ejection sea...   \n",
       "150003  A diagnostic apparatus for an evaporative fuel...   \n",
       "150004  A dual chamber fuel tank protector valve has a...   \n",
       "150005  An engine intake bypass system includes: an in...   \n",
       "\n",
       "                                         claims_text_dict  \\\n",
       "150001  {1: 'An actuation arrangement for a thrust rev...   \n",
       "150002  {1: 'A rocket catapult assembly for use in an ...   \n",
       "150003  {1: 'A diagnostic apparatus for an evaporative...   \n",
       "150004  {1: 'A fuel tank protector valve comprising:,a...   \n",
       "150005  {1: 'An engine intake bypass system comprising...   \n",
       "\n",
       "                                               claim_tree  \n",
       "150001  {'root': 'An actuation arrangement  [LB] for a...  \n",
       "150002  {'root': 'A rocket catapult assembly  [LB] for...  \n",
       "150003  {'root': 'A diagnostic apparatus  [LB] for an ...  \n",
       "150004  {'root': 'A fuel tank protector valve comprisi...  \n",
       "150005  {'root': 'An engine intake bypass system compr...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "p4h304zxryHa",
    "outputId": "21e35f81-781c-46ce-f4ec-c4f255c1d4cc"
   },
   "outputs": [],
   "source": [
    "df.to_csv('./uspto_df_segmented_claims_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the list of segments with output for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df['claim_tree'].apply(create_segments_list)\n",
    "df[['claim_segments', 'claim_segments_binary']] = pd.DataFrame(output.tolist(),index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./uspto_df_final_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of sequence sentences of a segmented claim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tree = df.loc[3400,'claim_tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'root': 'A cartridge configured  [LB] for a non-lethal self-protection system, the cartridge comprising', 'components': [':,a) a housing having [sub] a barrel;', ' b) [sub] a compressed gas vessel carried by the housing and containing [sub] a compressed gas, the compressed gas vessel having two positions comprising: i) [sub] a retained position farther from the barrel, and ii) a released position closer to the barrel;', ' c) a spring carried by the housing to bias the compressed gas vessel towards the released position;', ' d) a retainer carried by the housing and selectively retaining the compressed gas vessel in the retained position;', ' e) a projectile carried by the housing and positioned in front of the compressed gas vessel, the projectile containing [sub] an irritant;', ' f) a diffuser positioned between the projectile and the compressed gas vessel, the diffuser comprising [sub] a passage therethrough configured to spread out gas from the compressed gas vessel behind the projectile;', ' g) a cannula carried by the diffuser and having [sub] a sharp tip positioned to pierce the compressed gas vessel in the released position to release the compressed gas;', ' and,h) [sub] an annular seal carried by the housing and circumscribing the projectile and extending between the projectile and the housing to retain the projectile in the housing until the compressed gas is released from the compressed gas vessel.,;'], 'relations': ''}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result, final_result_binary = create_segments_list(example_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_result)== len(final_result_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./220503_df_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ornamental', 'design', 'for', 'a', 'hot', 'dog', 'pet', 'treat,', 'as', 'shown', 'and', 'described.']\n",
      "The ornamental design for a hot dog pet treat, as shown and described.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df['claim_segments'][0])\n",
    "print(df['claims_text'][0])\n",
    "print(len(df['claim_segments'][0])==len(df['claims_text'][0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other useful Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "TKxncjVuslz4"
   },
   "outputs": [],
   "source": [
    "def is_only_relation(text):\n",
    "    R = re.findall(':',text)\n",
    "    if R == []:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3kUqBMhKTPu",
    "outputId": "73c5a5a8-0ef1-4ec4-9372-4682ac7a5275"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['frontal portion'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('a headband member having a frontal portion and a mirror'.strip()).noun_phrases[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3paHBtZHaLTO"
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZslNEYQABxd",
    "outputId": "221e32d9-345f-4807-b540-5e553c475b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye shield member', 'frontal portion']\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob('an eye shield member removably secured to said frontal portion.')\n",
    "print(blob.noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75WIgaMfaEVv"
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize('a receive antenna configured to control generation of an ultra-wideband radar signal and reception of one or more resultant signals;the transmit antenna is angled relative to the receive antenna.')\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    for (word, tag) in tagged:\n",
    "        if tag == 'NP': # If the word is a proper noun\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "0RL2oTJ3sumP"
   },
   "outputs": [],
   "source": [
    "#get syonymes of a word\n",
    "#this needs lemmatisation before\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def synonym_extractor(phrase):\n",
    "    synonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(phrase):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwGh1XRSmgiN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
